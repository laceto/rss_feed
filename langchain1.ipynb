{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "  \n",
    "# Define the input file path  \n",
    "input_file_path = 'output/feeds2025-07-31.txt'  \n",
    "  \n",
    "# Read the tab-delimited file into a DataFrame  \n",
    "df = pd.read_csv(input_file_path, delimiter='\\t')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>guid</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>pubDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cnbc.com/2025/07/30/microsoft-mark...</td>\n",
       "      <td>108179389</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108179389</td>\n",
       "      <td>False</td>\n",
       "      <td>Microsoft tops $4 trillion in market cap after...</td>\n",
       "      <td>Based on its post-market trading, Microsoft ha...</td>\n",
       "      <td>Wed, 30 Jul 2025 22:27:00 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cnbc.com/2025/07/30/metas-reality-...</td>\n",
       "      <td>108178021</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108178021</td>\n",
       "      <td>False</td>\n",
       "      <td>Meta’s Reality Labs posts $4.53 billion loss i...</td>\n",
       "      <td>Meta’s Reality Labs posts $4.53 billion loss i...</td>\n",
       "      <td>Wed, 30 Jul 2025 20:20:49 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.cnbc.com/2025/07/25/india-under-pr...</td>\n",
       "      <td>108171329</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108171329</td>\n",
       "      <td>False</td>\n",
       "      <td>Trump has slapped steep tariffs on India. Here...</td>\n",
       "      <td>U.S. President Donald Trump on Wednesday annou...</td>\n",
       "      <td>Thu, 31 Jul 2025 04:28:17 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.cnbc.com/2025/07/31/trumps-aug-1-t...</td>\n",
       "      <td>108178228</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108178228</td>\n",
       "      <td>False</td>\n",
       "      <td>Trump’s tariff deadline is near. Here’s a look...</td>\n",
       "      <td>The U.S. has managed to make only eight deals ...</td>\n",
       "      <td>Thu, 31 Jul 2025 03:49:02 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.cnbc.com/2025/07/30/fed-leaves-int...</td>\n",
       "      <td>108179045</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108179045</td>\n",
       "      <td>False</td>\n",
       "      <td>Divided Fed holds key interest rate steady, de...</td>\n",
       "      <td>A divided Federal Reserve on Wednesday voted t...</td>\n",
       "      <td>Wed, 30 Jul 2025 20:08:27 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>https://www.cnbc.com/2025/07/27/trump-european...</td>\n",
       "      <td>108175589</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108175589</td>\n",
       "      <td>False</td>\n",
       "      <td>Trump announces EU trade deal with 15% tariffs</td>\n",
       "      <td>President Donald Trump and European Commission...</td>\n",
       "      <td>Sun, 27 Jul 2025 22:59:02 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>https://www.cnbc.com/2025/07/27/lutnick-trump-...</td>\n",
       "      <td>108177448</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108177448</td>\n",
       "      <td>False</td>\n",
       "      <td>Lutnick: Trump wants 'good enough' EU trade of...</td>\n",
       "      <td>President Donald Trump is set to hold trade ta...</td>\n",
       "      <td>Sun, 27 Jul 2025 15:08:51 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>https://www.cnbc.com/2025/07/27/how-trump-and-...</td>\n",
       "      <td>108176204</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108176204</td>\n",
       "      <td>False</td>\n",
       "      <td>How Trump and trade wars pushed Russia and Ukr...</td>\n",
       "      <td>It's easy to forget Russian and Ukrainian sold...</td>\n",
       "      <td>Sun, 27 Jul 2025 06:20:47 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>https://www.cnbc.com/2025/07/27/global-week-ah...</td>\n",
       "      <td>108177038</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108177038</td>\n",
       "      <td>False</td>\n",
       "      <td>Global week ahead: Crunch time for trade talks...</td>\n",
       "      <td>The week has become even trickier to predict, ...</td>\n",
       "      <td>Sun, 27 Jul 2025 06:12:01 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>https://www.cnbc.com/2025/07/26/eu-chief-to-me...</td>\n",
       "      <td>108177406</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108177406</td>\n",
       "      <td>False</td>\n",
       "      <td>EU chief to meet Trump in Scotland in push to ...</td>\n",
       "      <td>\\I think we have a good 50/50 chance. That's a...</td>\n",
       "      <td>Sat, 26 Jul 2025 10:22:53 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  link       guid  \\\n",
       "0    https://www.cnbc.com/2025/07/30/microsoft-mark...  108179389   \n",
       "1    https://www.cnbc.com/2025/07/30/metas-reality-...  108178021   \n",
       "2    https://www.cnbc.com/2025/07/25/india-under-pr...  108171329   \n",
       "3    https://www.cnbc.com/2025/07/31/trumps-aug-1-t...  108178228   \n",
       "4    https://www.cnbc.com/2025/07/30/fed-leaves-int...  108179045   \n",
       "..                                                 ...        ...   \n",
       "445  https://www.cnbc.com/2025/07/27/trump-european...  108175589   \n",
       "446  https://www.cnbc.com/2025/07/27/lutnick-trump-...  108177448   \n",
       "447  https://www.cnbc.com/2025/07/27/how-trump-and-...  108176204   \n",
       "448  https://www.cnbc.com/2025/07/27/global-week-ah...  108177038   \n",
       "449  https://www.cnbc.com/2025/07/26/eu-chief-to-me...  108177406   \n",
       "\n",
       "              type         id  sponsored  \\\n",
       "0    cnbcnewsstory  108179389      False   \n",
       "1    cnbcnewsstory  108178021      False   \n",
       "2    cnbcnewsstory  108171329      False   \n",
       "3    cnbcnewsstory  108178228      False   \n",
       "4    cnbcnewsstory  108179045      False   \n",
       "..             ...        ...        ...   \n",
       "445  cnbcnewsstory  108175589      False   \n",
       "446  cnbcnewsstory  108177448      False   \n",
       "447  cnbcnewsstory  108176204      False   \n",
       "448  cnbcnewsstory  108177038      False   \n",
       "449  cnbcnewsstory  108177406      False   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Microsoft tops $4 trillion in market cap after...   \n",
       "1    Meta’s Reality Labs posts $4.53 billion loss i...   \n",
       "2    Trump has slapped steep tariffs on India. Here...   \n",
       "3    Trump’s tariff deadline is near. Here’s a look...   \n",
       "4    Divided Fed holds key interest rate steady, de...   \n",
       "..                                                 ...   \n",
       "445     Trump announces EU trade deal with 15% tariffs   \n",
       "446  Lutnick: Trump wants 'good enough' EU trade of...   \n",
       "447  How Trump and trade wars pushed Russia and Ukr...   \n",
       "448  Global week ahead: Crunch time for trade talks...   \n",
       "449  EU chief to meet Trump in Scotland in push to ...   \n",
       "\n",
       "                                           description  \\\n",
       "0    Based on its post-market trading, Microsoft ha...   \n",
       "1    Meta’s Reality Labs posts $4.53 billion loss i...   \n",
       "2    U.S. President Donald Trump on Wednesday annou...   \n",
       "3    The U.S. has managed to make only eight deals ...   \n",
       "4    A divided Federal Reserve on Wednesday voted t...   \n",
       "..                                                 ...   \n",
       "445  President Donald Trump and European Commission...   \n",
       "446  President Donald Trump is set to hold trade ta...   \n",
       "447  It's easy to forget Russian and Ukrainian sold...   \n",
       "448  The week has become even trickier to predict, ...   \n",
       "449  \\I think we have a good 50/50 chance. That's a...   \n",
       "\n",
       "                           pubDate  \n",
       "0    Wed, 30 Jul 2025 22:27:00 GMT  \n",
       "1    Wed, 30 Jul 2025 20:20:49 GMT  \n",
       "2    Thu, 31 Jul 2025 04:28:17 GMT  \n",
       "3    Thu, 31 Jul 2025 03:49:02 GMT  \n",
       "4    Wed, 30 Jul 2025 20:08:27 GMT  \n",
       "..                             ...  \n",
       "445  Sun, 27 Jul 2025 22:59:02 GMT  \n",
       "446  Sun, 27 Jul 2025 15:08:51 GMT  \n",
       "447  Sun, 27 Jul 2025 06:20:47 GMT  \n",
       "448  Sun, 27 Jul 2025 06:12:01 GMT  \n",
       "449  Sat, 26 Jul 2025 10:22:53 GMT  \n",
       "\n",
       "[450 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import os  \n",
    "  \n",
    "# Define the input folder path  \n",
    "input_folder_path = 'output'  \n",
    "  \n",
    "# List to store individual DataFrames  \n",
    "dataframes = []  \n",
    "  \n",
    "# Iterate through all .txt files in the specified folder  \n",
    "for filename in os.listdir(input_folder_path):  \n",
    "    if filename.endswith('.txt'):  \n",
    "        # Construct the full file path  \n",
    "        file_path = os.path.join(input_folder_path, filename)  \n",
    "          \n",
    "        # Read the tab-delimited file into a DataFrame  \n",
    "        df = pd.read_csv(file_path, delimiter='\\t')  \n",
    "          \n",
    "        # Append the DataFrame to the list  \n",
    "        dataframes.append(df)  \n",
    "  \n",
    "# Concatenate all DataFrames by rows  \n",
    "combined_df = pd.concat(dataframes, ignore_index=True)  \n",
    "  \n",
    "# # Display the combined DataFrame  \n",
    "# print(combined_df)  \n",
    "  \n",
    "# # Optionally, save the combined DataFrame to a new file  \n",
    "# output_file_path = 'combined_output.txt'  \n",
    "# combined_df.to_csv(output_file_path, sep='\\t', index=False)  \n",
    "  \n",
    "# print(f\"Combined DataFrame has been written to {output_file_path}\")  \n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source_File</th>\n",
       "      <th>link</th>\n",
       "      <th>guid</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>pubDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feeds.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/30/microsoft-mark...</td>\n",
       "      <td>108179389</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108179389</td>\n",
       "      <td>False</td>\n",
       "      <td>Microsoft tops $4 trillion in market cap after...</td>\n",
       "      <td>Based on its post-market trading, Microsoft ha...</td>\n",
       "      <td>Wed, 30 Jul 2025 22:27:00 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feeds.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/30/metas-reality-...</td>\n",
       "      <td>108178021</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108178021</td>\n",
       "      <td>False</td>\n",
       "      <td>Meta’s Reality Labs posts $4.53 billion loss i...</td>\n",
       "      <td>Meta’s Reality Labs posts $4.53 billion loss i...</td>\n",
       "      <td>Wed, 30 Jul 2025 20:20:49 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feeds.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/25/india-under-pr...</td>\n",
       "      <td>108171329</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108171329</td>\n",
       "      <td>False</td>\n",
       "      <td>Trump has slapped steep tariffs on India. Here...</td>\n",
       "      <td>U.S. President Donald Trump on Wednesday annou...</td>\n",
       "      <td>Thu, 31 Jul 2025 04:28:17 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeds.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/31/trumps-aug-1-t...</td>\n",
       "      <td>108178228</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108178228</td>\n",
       "      <td>False</td>\n",
       "      <td>Trump’s tariff deadline is near. Here’s a look...</td>\n",
       "      <td>The U.S. has managed to make only eight deals ...</td>\n",
       "      <td>Thu, 31 Jul 2025 03:49:02 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeds.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/30/fed-leaves-int...</td>\n",
       "      <td>108179045</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108179045</td>\n",
       "      <td>False</td>\n",
       "      <td>Divided Fed holds key interest rate steady, de...</td>\n",
       "      <td>A divided Federal Reserve on Wednesday voted t...</td>\n",
       "      <td>Wed, 30 Jul 2025 20:08:27 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>feeds2025-08-01.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/31/tesla-autopilo...</td>\n",
       "      <td>108180018</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108180018</td>\n",
       "      <td>False</td>\n",
       "      <td>Tesla Autopilot plaintiffs seek $345 million i...</td>\n",
       "      <td>Jury deliberations have begun in a Tesla trial...</td>\n",
       "      <td>Fri, 01 Aug 2025 00:21:32 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>feeds2025-08-01.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/31/tim-cook-apple...</td>\n",
       "      <td>108180109</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108180109</td>\n",
       "      <td>False</td>\n",
       "      <td>Facing questions on AI strategy, Tim Cook says...</td>\n",
       "      <td>\\The way that we look at AI is that it's one o...</td>\n",
       "      <td>Thu, 31 Jul 2025 23:36:37 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>feeds2025-08-01.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/07/31/figmas-top-vcs...</td>\n",
       "      <td>108179917</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108179917</td>\n",
       "      <td>False</td>\n",
       "      <td>Figma's top VCs are sitting on $24 billion wor...</td>\n",
       "      <td>Venture capital firms have been waiting for bi...</td>\n",
       "      <td>Fri, 01 Aug 2025 01:42:15 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>feeds2025-08-01.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/08/01/how-asian-coun...</td>\n",
       "      <td>108180161</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108180161</td>\n",
       "      <td>False</td>\n",
       "      <td>How countries are reacting to Trump's latest t...</td>\n",
       "      <td>The White House also announced a 40% tariff ra...</td>\n",
       "      <td>Fri, 01 Aug 2025 08:26:05 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>feeds2025-08-01.txt</td>\n",
       "      <td>https://www.cnbc.com/2025/08/01/trump-rejigs-t...</td>\n",
       "      <td>108180141</td>\n",
       "      <td>cnbcnewsstory</td>\n",
       "      <td>108180141</td>\n",
       "      <td>False</td>\n",
       "      <td>Trump modifies tariff rates ahead of deadline,...</td>\n",
       "      <td>All goods that are considered to have been tra...</td>\n",
       "      <td>Fri, 01 Aug 2025 12:00:40 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source_File                                               link  \\\n",
       "0              feeds.txt  https://www.cnbc.com/2025/07/30/microsoft-mark...   \n",
       "1              feeds.txt  https://www.cnbc.com/2025/07/30/metas-reality-...   \n",
       "2              feeds.txt  https://www.cnbc.com/2025/07/25/india-under-pr...   \n",
       "3              feeds.txt  https://www.cnbc.com/2025/07/31/trumps-aug-1-t...   \n",
       "4              feeds.txt  https://www.cnbc.com/2025/07/30/fed-leaves-int...   \n",
       "..                   ...                                                ...   \n",
       "374  feeds2025-08-01.txt  https://www.cnbc.com/2025/07/31/tesla-autopilo...   \n",
       "375  feeds2025-08-01.txt  https://www.cnbc.com/2025/07/31/tim-cook-apple...   \n",
       "376  feeds2025-08-01.txt  https://www.cnbc.com/2025/07/31/figmas-top-vcs...   \n",
       "393  feeds2025-08-01.txt  https://www.cnbc.com/2025/08/01/how-asian-coun...   \n",
       "394  feeds2025-08-01.txt  https://www.cnbc.com/2025/08/01/trump-rejigs-t...   \n",
       "\n",
       "          guid           type         id  sponsored  \\\n",
       "0    108179389  cnbcnewsstory  108179389      False   \n",
       "1    108178021  cnbcnewsstory  108178021      False   \n",
       "2    108171329  cnbcnewsstory  108171329      False   \n",
       "3    108178228  cnbcnewsstory  108178228      False   \n",
       "4    108179045  cnbcnewsstory  108179045      False   \n",
       "..         ...            ...        ...        ...   \n",
       "374  108180018  cnbcnewsstory  108180018      False   \n",
       "375  108180109  cnbcnewsstory  108180109      False   \n",
       "376  108179917  cnbcnewsstory  108179917      False   \n",
       "393  108180161  cnbcnewsstory  108180161      False   \n",
       "394  108180141  cnbcnewsstory  108180141      False   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Microsoft tops $4 trillion in market cap after...   \n",
       "1    Meta’s Reality Labs posts $4.53 billion loss i...   \n",
       "2    Trump has slapped steep tariffs on India. Here...   \n",
       "3    Trump’s tariff deadline is near. Here’s a look...   \n",
       "4    Divided Fed holds key interest rate steady, de...   \n",
       "..                                                 ...   \n",
       "374  Tesla Autopilot plaintiffs seek $345 million i...   \n",
       "375  Facing questions on AI strategy, Tim Cook says...   \n",
       "376  Figma's top VCs are sitting on $24 billion wor...   \n",
       "393  How countries are reacting to Trump's latest t...   \n",
       "394  Trump modifies tariff rates ahead of deadline,...   \n",
       "\n",
       "                                           description  \\\n",
       "0    Based on its post-market trading, Microsoft ha...   \n",
       "1    Meta’s Reality Labs posts $4.53 billion loss i...   \n",
       "2    U.S. President Donald Trump on Wednesday annou...   \n",
       "3    The U.S. has managed to make only eight deals ...   \n",
       "4    A divided Federal Reserve on Wednesday voted t...   \n",
       "..                                                 ...   \n",
       "374  Jury deliberations have begun in a Tesla trial...   \n",
       "375  \\The way that we look at AI is that it's one o...   \n",
       "376  Venture capital firms have been waiting for bi...   \n",
       "393  The White House also announced a 40% tariff ra...   \n",
       "394  All goods that are considered to have been tra...   \n",
       "\n",
       "                           pubDate  \n",
       "0    Wed, 30 Jul 2025 22:27:00 GMT  \n",
       "1    Wed, 30 Jul 2025 20:20:49 GMT  \n",
       "2    Thu, 31 Jul 2025 04:28:17 GMT  \n",
       "3    Thu, 31 Jul 2025 03:49:02 GMT  \n",
       "4    Wed, 30 Jul 2025 20:08:27 GMT  \n",
       "..                             ...  \n",
       "374  Fri, 01 Aug 2025 00:21:32 GMT  \n",
       "375  Thu, 31 Jul 2025 23:36:37 GMT  \n",
       "376  Fri, 01 Aug 2025 01:42:15 GMT  \n",
       "393  Fri, 01 Aug 2025 08:26:05 GMT  \n",
       "394  Fri, 01 Aug 2025 12:00:40 GMT  \n",
       "\n",
       "[222 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import os  \n",
    "  \n",
    "# Define the input folder path  \n",
    "input_folder_path = 'output'  \n",
    "  \n",
    "# List to store individual DataFrames  \n",
    "dataframes = []  \n",
    "  \n",
    "# Iterate through all .txt files in the specified folder  \n",
    "for filename in os.listdir(input_folder_path):  \n",
    "    if filename.endswith('.txt'):  \n",
    "        # Construct the full file path  \n",
    "        file_path = os.path.join(input_folder_path, filename)  \n",
    "          \n",
    "        # Read the tab-delimited file into a DataFrame  \n",
    "        df = pd.read_csv(file_path, delimiter='\\t')  \n",
    "          \n",
    "        # Add a new column for the filename  \n",
    "        df.insert(0, 'Source_File', filename)  # Insert at position 0  \n",
    "          \n",
    "        # Append the DataFrame to the list  \n",
    "        dataframes.append(df)  \n",
    "  \n",
    "# Concatenate all DataFrames by rows  \n",
    "combined_df = pd.concat(dataframes, ignore_index=True)  \n",
    "\n",
    "combined_df = combined_df.drop_duplicates(subset='title', keep='first')  \n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = connection.handle_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28mself\u001b[39m._connect(request)\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpcore\\_sync\\connection.py:156\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mstart_tls\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     stream = stream.start_tls(**kwargs)\n\u001b[32m    157\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpcore\\_backends\\sync.py:154\u001b[39m, in \u001b[36mSyncStream.start_tls\u001b[39m\u001b[34m(self, ssl_context, server_hostname, timeout)\u001b[39m\n\u001b[32m    150\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    151\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    152\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    153\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(value)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1010)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\openai\\_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m    973\u001b[39m         request,\n\u001b[32m    974\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m    975\u001b[39m         **kwargs,\n\u001b[32m    976\u001b[39m     )\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m    915\u001b[39m     request,\n\u001b[32m    916\u001b[39m     auth=auth,\n\u001b[32m    917\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m    918\u001b[39m     history=[],\n\u001b[32m    919\u001b[39m )\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m    943\u001b[39m         request,\n\u001b[32m    944\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m    945\u001b[39m         history=history,\n\u001b[32m    946\u001b[39m     )\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = transport.handle_request(request)\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(value)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1010)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m llm = OpenAI(\n\u001b[32m      4\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4.1-nano\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     temperature = \u001b[32m0\u001b[39m\n\u001b[32m      6\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m llm.invoke(\u001b[33m'\u001b[39m\u001b[33mchi era giacomo mancini\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:389\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    380\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m     **kwargs: Any,\n\u001b[32m    386\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    387\u001b[39m     config = ensure_config(config)\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m         \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m    390\u001b[39m             [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    391\u001b[39m             stop=stop,\n\u001b[32m    392\u001b[39m             callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    393\u001b[39m             tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    394\u001b[39m             metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    395\u001b[39m             run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    396\u001b[39m             run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    397\u001b[39m             **kwargs,\n\u001b[32m    398\u001b[39m         )\n\u001b[32m    399\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    400\u001b[39m         .text\n\u001b[32m    401\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    759\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    763\u001b[39m     **kwargs: Any,\n\u001b[32m    764\u001b[39m ) -> LLMResult:\n\u001b[32m    765\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:973\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     run_managers = [\n\u001b[32m    960\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    961\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    971\u001b[39m         )\n\u001b[32m    972\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_helper(\n\u001b[32m    974\u001b[39m         prompts,\n\u001b[32m    975\u001b[39m         stop,\n\u001b[32m    976\u001b[39m         run_managers,\n\u001b[32m    977\u001b[39m         new_arg_supported=\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[32m    978\u001b[39m         **kwargs,\n\u001b[32m    979\u001b[39m     )\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m    981\u001b[39m     run_managers = [\n\u001b[32m    982\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m    983\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    990\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m    991\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    782\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    783\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m     **kwargs: Any,\n\u001b[32m    789\u001b[39m ) -> LLMResult:\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    791\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m             \u001b[38;5;28mself\u001b[39m._generate(\n\u001b[32m    793\u001b[39m                 prompts,\n\u001b[32m    794\u001b[39m                 stop=stop,\n\u001b[32m    795\u001b[39m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[32m    796\u001b[39m                 run_manager=run_managers[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    797\u001b[39m                 **kwargs,\n\u001b[32m    798\u001b[39m             )\n\u001b[32m    799\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    800\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    801\u001b[39m         )\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    803\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\langchain_openai\\llms\\base.py:330\u001b[39m, in \u001b[36mBaseOpenAI._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     choices.append(\n\u001b[32m    315\u001b[39m         {\n\u001b[32m    316\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: generation.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    327\u001b[39m         }\n\u001b[32m    328\u001b[39m     )\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.client.create(prompt=_prompts, **params)\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    332\u001b[39m         \u001b[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[32m    333\u001b[39m         \u001b[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[32m    334\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\openai\\resources\\completions.py:541\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    514\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    540\u001b[39m ) -> Completion | Stream[Completion]:\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    542\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    543\u001b[39m         body=maybe_transform(\n\u001b[32m    544\u001b[39m             {\n\u001b[32m    545\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m    546\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m    547\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbest_of\u001b[39m\u001b[33m\"\u001b[39m: best_of,\n\u001b[32m    548\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mecho\u001b[39m\u001b[33m\"\u001b[39m: echo,\n\u001b[32m    549\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m    550\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m    551\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m    552\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m    553\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m    554\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m    555\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m    556\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    557\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m    558\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m    559\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msuffix\u001b[39m\u001b[33m\"\u001b[39m: suffix,\n\u001b[32m    560\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m    561\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m    562\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m    563\u001b[39m             },\n\u001b[32m    564\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m    565\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m    566\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m    567\u001b[39m         ),\n\u001b[32m    568\u001b[39m         options=make_request_options(\n\u001b[32m    569\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m    570\u001b[39m         ),\n\u001b[32m    571\u001b[39m         cast_to=Completion,\n\u001b[32m    572\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    573\u001b[39m         stream_cls=Stream[Completion],\n\u001b[32m    574\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laceto\\AppData\\Local\\r-miniconda\\Lib\\site-packages\\openai\\_base_client.py:1004\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1001\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1003\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRaising connection error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request=request) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1006\u001b[39m log.debug(\n\u001b[32m   1007\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1008\u001b[39m     request.method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     response.headers,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m   1014\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mx-request-id\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mAPIConnectionError\u001b[39m: Connection error."
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature = 0\n",
    "    )\n",
    "\n",
    "llm.invoke('chi era giacomo mancini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "        template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "# user question\n",
    "question = \"what is langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to facilitate the integration of LLMs into various applications, enabling developers to build complex systems that can perform tasks such as natural language understanding, generation, and interaction. Langchain typically offers components for managing prompts, handling memory, chaining together multiple LLM calls, and interfacing with external data sources or APIs. This framework is particularly useful for creating chatbots, virtual assistants, and other AI-driven applications that require sophisticated language processing capabilities.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 11, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BnL0Z5nTgZkkUkFyVsvrC8VDuOFaz', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--1557084a-d853-4054-a080-f8dc13255811-0', usage_metadata={'input_tokens': 11, 'output_tokens': 115, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to facilitate the integration of LLMs into various applications, enabling developers to build complex systems that can perform tasks such as natural language understanding, generation, and interaction. Langchain supports features like prompt management, chaining of LLM calls, and integration with external data sources, making it easier to create sophisticated applications that can process and generate human-like text.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 17, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BnL0uXC1aWu6mfLSsuhIOPAR0zUeB', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--be82f10e-fd7c-46f2-b402-6bed364f7aeb-0', usage_metadata={'input_tokens': 17, 'output_tokens': 98, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to facilitate the integration of LLMs into various applications, enabling developers to build complex systems that can perform tasks such as natural language understanding, generation, and interaction. Langchain supports features like prompt management, chaining of LLM calls, and integration with external data sources, making it easier to create sophisticated language-based applications.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(question)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"L'Italia ha vinto i Mondiali di calcio del 2006. La finale si è svolta il 9 luglio 2006 a Berlino, e l'Italia ha battuto la Francia ai calci di rigore, dopo che la partita era terminata 1-1 nei tempi regolamentari e supplementari.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('chi ha vinto i mondiali di calcio del 2006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [\n",
    "    {'question': \"what is langchain\"},\n",
    "    {'question': \"who can use langchain\"},\n",
    "    {'question': \"what can I build with langchain\"},\n",
    "    {'question': \"is langchain suitable for building excel macro\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'what is langchain'},\n",
       " {'question': 'who can use langchain'},\n",
       " {'question': 'what can I build with langchain'},\n",
       " {'question': 'is langchain suitable for building excel macro'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to facilitate the integration of LLMs into various applications, enabling developers to build complex systems that can perform tasks such as natural language understanding, generation, and interaction. Langchain supports features like prompt management, chaining of LLM calls, and integration with external data sources, making it easier to create sophisticated AI-driven applications.',\n",
       " 'Langchain can be used by a wide range of individuals and organizations, including:\\n\\n1. **Developers**: Software developers and engineers can use Langchain to build applications that leverage natural language processing (NLP) capabilities. It provides tools and frameworks to integrate language models into various applications.\\n\\n2. **Data Scientists**: Data scientists can utilize Langchain to analyze and process large volumes of text data, perform sentiment analysis, text classification, and other NLP tasks.\\n\\n3. **Researchers**: Academic and industry researchers working in the field of artificial intelligence and NLP can use Langchain to experiment with language models, conduct studies, and develop new algorithms.\\n\\n4. **Businesses**: Companies can use Langchain to enhance customer service through chatbots, automate content generation, improve search functionality, and gain insights from textual data.\\n\\n5. **Educators and Students**: Educators can use Langchain as a teaching tool to demonstrate NLP concepts, while students can use it to learn and experiment with language models.\\n\\n6. **Content Creators**: Writers, marketers, and content creators can use Langchain to generate ideas, draft content, and optimize text for SEO.\\n\\nOverall, Langchain is designed to be accessible to anyone interested in leveraging the power of language models for various applications and purposes.',\n",
       " 'Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). With Langchain, you can build a variety of applications, including:\\n\\n1. **Chatbots and Conversational Agents**: Create interactive chatbots that can understand and respond to user queries in natural language.\\n\\n2. **Question Answering Systems**: Develop systems that can answer questions based on a given context or dataset.\\n\\n3. **Text Summarization Tools**: Build applications that can summarize long documents or articles into concise summaries.\\n\\n4. **Content Generation**: Generate creative content such as articles, stories, or social media posts using LLMs.\\n\\n5. **Code Generation and Assistance**: Create tools that can assist in writing code or generate code snippets based on natural language descriptions.\\n\\n6. **Sentiment Analysis**: Develop applications that can analyze and interpret the sentiment of text data.\\n\\n7. **Translation Services**: Build systems that can translate text from one language to another.\\n\\n8. **Data Extraction and Structuring**: Extract structured information from unstructured text data.\\n\\n9. **Personalized Recommendations**: Create recommendation systems that suggest content or products based on user preferences and behavior.\\n\\n10. **Automated Email Responses**: Develop systems that can automatically draft and respond to emails.\\n\\nLangchain provides components and abstractions that make it easier to integrate LLMs into these applications, allowing developers to focus on building features rather than dealing with the complexities of model management and deployment.',\n",
       " 'Langchain is not specifically designed for building Excel macros. Langchain is a framework for developing applications powered by language models, typically used for tasks involving natural language processing, such as chatbots, text generation, and information retrieval. Excel macros, on the other hand, are typically written in VBA (Visual Basic for Applications) and are used to automate tasks within Excel.\\n\\nIf you are looking to automate tasks in Excel, you would typically use VBA or other tools specifically designed for Excel automation, such as Python libraries like openpyxl or pandas for more advanced data manipulation. Langchain would not be suitable for this purpose unless you are looking to integrate language model capabilities into your Excel automation tasks, which would be a more complex and specialized use case.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to facilitate the integration of LLMs into various applications, enabling developers to build complex systems that can perform tasks such as natural language understanding, generation, and interaction. Langchain supports features like prompt management, chaining of LLM calls, and integration with external data sources, making it easier to create sophisticated applications that can process and generate human-like text.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "chain.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). It provides tools and abstractions to facilitate the integration of LLMs into various applications, enabling developers to build complex systems that can perform tasks such as natural language understanding, generation, and interaction. Langchain supports features like prompt management, chaining multiple LLM calls, and integrating with external data sources, making it easier to create sophisticated AI-driven applications.',\n",
       " 'Langchain can be used by a variety of individuals and organizations, including:\\n\\n1. **Developers**: Software developers and engineers can use Langchain to build applications that leverage natural language processing (NLP) capabilities. It provides tools and frameworks to integrate language models into applications.\\n\\n2. **Data Scientists**: Data scientists can use Langchain to experiment with and deploy language models for tasks such as text analysis, sentiment analysis, and other NLP-related projects.\\n\\n3. **Researchers**: Academic and industry researchers working in the field of artificial intelligence and NLP can use Langchain to test hypotheses, conduct experiments, and develop new models.\\n\\n4. **Businesses**: Companies can use Langchain to enhance their products and services with language understanding capabilities, such as chatbots, virtual assistants, and automated customer support systems.\\n\\n5. **Educators and Students**: Educators can use Langchain as a teaching tool to demonstrate NLP concepts, while students can use it to learn and experiment with language models.\\n\\n6. **Content Creators**: Writers, marketers, and other content creators can use Langchain to generate text, brainstorm ideas, and automate content creation processes.\\n\\nOverall, Langchain is designed to be accessible to anyone interested in working with language models, regardless of their technical expertise.',\n",
       " 'Langchain is a framework designed to simplify the development of applications that leverage large language models (LLMs). With Langchain, you can build a variety of applications, including:\\n\\n1. **Chatbots and Conversational Agents**: Create interactive chatbots that can understand and respond to user queries in natural language.\\n\\n2. **Question Answering Systems**: Develop systems that can answer questions based on a given context or dataset.\\n\\n3. **Text Summarization Tools**: Build applications that can summarize long documents or articles into concise summaries.\\n\\n4. **Content Generation Platforms**: Generate creative content such as articles, stories, or social media posts.\\n\\n5. **Translation Services**: Implement language translation tools that can convert text from one language to another.\\n\\n6. **Sentiment Analysis Applications**: Analyze text to determine the sentiment or emotional tone.\\n\\n7. **Information Retrieval Systems**: Create systems that can search and retrieve relevant information from large datasets.\\n\\n8. **Personalized Recommendation Engines**: Develop systems that provide personalized recommendations based on user preferences and behavior.\\n\\n9. **Automated Code Generation**: Build tools that can generate code snippets or assist in programming tasks.\\n\\n10. **Data Extraction and Processing**: Extract structured information from unstructured text data.\\n\\nLangchain provides the necessary components and abstractions to integrate LLMs into these applications, making it easier to handle tasks like prompt management, memory, and interaction with external data sources.',\n",
       " 'Langchain is not specifically designed for building Excel macros. Langchain is a framework for developing applications powered by language models, typically used for tasks involving natural language processing, such as chatbots, text generation, and information retrieval. Excel macros, on the other hand, are typically written in VBA (Visual Basic for Applications) and are used to automate tasks within Excel.\\n\\nIf you are looking to automate tasks in Excel, you would typically use VBA or other tools like Python with libraries such as openpyxl or pandas. Langchain would not be suitable for this purpose unless you are looking to integrate language model capabilities into your Excel automation tasks, which would be a more complex and specialized use case.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(qs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
